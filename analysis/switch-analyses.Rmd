---
title: "individual clusters analyses"
output: html_document
date: "2023-04-05"
---

# load packages

```{r}
library(tidyverse)
library(ggplot2)
library(ggthemes)
library(stringdist)
library(lme4)
library(lmerTest)
library(broom.mixed)
setwd(here::here())
library(boot)
library(irr)
library(optimx)
getwd()
```

# define model functions

```{r}
# Function to clean column names by replacing special characters with underscores
clean_column_names <- function(column_names) {
  str_replace_all(column_names, "[^[:alnum:] ]", "_")
}

n_bootstrap = 1000


calculate_bootstrap_r_squared <- function(data, type, n_bootstrap, formula) {
  # Define an empty vector to store R-squared values
  r_squared_values <- numeric(n_bootstrap)
  
  # Calculate R-squared for each bootstrap sample
  for (i in 1:n_bootstrap) {
    # Generate random indices with replacement
    indices <- sample(nrow(data), replace = TRUE)
    
    # Subset data using the random indices
    sampled_data <- data[indices, ]

    # Fit your model using the sampled data
    if(type == "glmer"){
      model <- eval(bquote(glmer(.(formula), data = .(substitute(sampled_data)), family = binomial)))
      # Calculate R-squared and store it in the vector
      r_squared_values[i] <- MuMIn::r.squaredGLMM(model)[4]
                                                         
      }
    else{
      model <- lmer(formula, data = sampled_data, 
                    control=lmerControl(optimizer="optimx",
                                 optCtrl=list(method='nlminb')))
      # Calculate R-squared and store it in the vector
      r_squared_values[i] <- MuMIn::r.squaredGLMM(model)[2]
      }  
    
  }
  
  # Calculate confidence intervals of R-squared values
  ci_r_squared <- quantile(r_squared_values, c(0.025, 0.975))
  
  return(ci_r_squared)
}
    
  

# Define a function to fit the glmer model for each cleaned predictor column
fit_model <- function(df, column, type, dv, var_cutoff) {
  
  # calculate variance of the column

  var_col = var(df[column], na.rm = TRUE)
  
  if (var_col > var_cutoff) {
    
    if(type == "glmer"){
      model_formula <- as.formula(paste(dv, " ~ ", column, "+ (1 | subject)"))
      model <- glmer(model_formula, data = df, family = binomial)
      estimate <- fixef(model)[column]
      
      r_squared <- MuMIn::r.squaredGLMM(model)[4] # conditional delta R-squared
      ci_r_squared <- calculate_bootstrap_r_squared(data = df, type, n_bootstrap = n_bootstrap, formula = model_formula)
      
      }
    else { #if(type == "lmer") {
      model_formula <- as.formula(paste(dv, " ~ ", column, "+ (1 | subject)"))

      model <- lmer(model_formula, data = df, control=lmerControl(optimizer="optimx",
                                 optCtrl=list(method='nlminb')))
      estimate <- fixef(model)[column]
      r_squared <- MuMIn::r.squaredGLMM(model)[2] # conditional R-squared
      ci_r_squared <- calculate_bootstrap_r_squared(data = df, type, n_bootstrap = n_bootstrap, formula = model_formula)
    }
   
  
    aic <- AIC(model)
    bic <- BIC(model)
    
    log_likelihood <- as.numeric(logLik(model))
    n_obs <- nobs(model)
    
    result <- tibble(
      Predictor = column,
      Fixed_Effect = estimate,
      AIC = aic,
      BIC = bic,
      R_squared = r_squared,
      Log_Likelihood = log_likelihood,
      N_Observations = n_obs,
      R_squared_CI_lower = ci_r_squared[1],  # Lower bound of CI
      R_squared_CI_upper = ci_r_squared[2]   # Upper bound of CI
    )
    
    return(result)
    }
    else{
       return(NULL)
    }
}


```

# import switch method predictions

```{r}
foods = read_csv("../forager_test/output/foods_forager/switch_results.csv") %>%
  rowwise() %>% group_by(Subject, Switch_Method) %>% mutate(response_number = row_number())%>% 
  pivot_wider(names_from = Switch_Method, values_from = Switch_Value) %>%
  rename(subject = Subject, cluster = Fluency_Item) %>%
  mutate(subject = as.character(subject))%>%
  mutate(domain = "foods")

animals = read_csv("../forager_test/output/animals_forager/switch_results.csv") %>%
  rowwise() %>% group_by(Subject, Switch_Method) %>% mutate(response_number = row_number())%>% 
  pivot_wider(names_from = Switch_Method, values_from = Switch_Value) %>%
  rename(subject = Subject, cluster = Fluency_Item) %>%
  mutate(subject = as.character(subject))%>%
  mutate(domain = "animals")

occupations = read_csv("../forager_test/output/occupations_forager/switch_results.csv") %>%
  rowwise() %>% group_by(Subject, Switch_Method) %>% mutate(response_number = row_number())%>% 
  pivot_wider(names_from = Switch_Method, values_from = Switch_Value) %>%
  rename(subject = Subject, cluster = Fluency_Item) %>%
  mutate(subject = as.character(subject))%>%
  mutate(domain = "occupations")

all_domains = rbind(animals, foods, occupations)
```

## Figure 1: visualize cluster/switch designations
```{r}
lexical_sample = read_csv("../forager_test/output/animals_forager/lexical_results.csv") %>%
  filter(Subject == 50020) %>%
  group_by(Subject) %>% mutate(response_number = row_number())%>%
  filter(response_number %in% 34:41) %>% 
  rename(cluster = Fluency_Item, subject = Subject,
         semantic = Semantic_Similarity,
         phonological = Phonological_Similarity)%>%
  mutate(subject = as.character(subject))
  

switch_sample = animals %>% 
  filter(subject == 50020) %>%
  pivot_longer(names_to = "Switch_Method", 
               cols = simdrop:`multimodaldelta_alpha=1.0_rise=1.0_fall=1.0`) %>%
  filter(response_number %in% 34:41) %>%
  arrange(Switch_Method, response_number) %>%
  filter(Switch_Method %in% c("simdrop", "norms_associative", "norms_categorical",
                                   "delta_rise=0.75_fall=0.75",
                                   "multimodal_alpha=0.8", 
                                "multimodaldelta_alpha=0.6000000000000001_rise=0.75_fall=0.75",
                              "svd_cosine=0.2_gtom=0.9"))  %>%
  left_join(lexical_sample) %>%
  rename(Switch_Value = value) %>%
  pivot_longer(names_to = "type", cols = c(semantic, phonological)) %>%
  mutate(Switch_Method = as.factor(Switch_Method)) %>%
  group_by(Switch_Method, type) %>%
  mutate(row = row_number(),
         Switch_Method = fct_recode(Switch_Method, multimodal = "multimodal_alpha=0.8",
                                     delta = "delta_rise=0.75_fall=0.75",
                                    multimodal_delta = "multimodaldelta_alpha=1.0_rise=1.0_fall=0.25",
                                     simdrop = "simdrop",
                                     associative= "norms_associative",
                                    categorical = "norms_categorical"))%>%
  mutate(Switch_Method = fct_relevel(Switch_Method, 
                                     "associative","categorical",  "simdrop", "delta", "multimodal",
                                     "multimodal_delta"),
         Switch_Value = ifelse(Switch_Value == 1, "switch", "cluster"))%>%
  rename(method = Switch_Method,
         transition = Switch_Value)

clusterplot =switch_sample %>%
  filter(method == "associative")%>%
  ggplot(aes(x = row, y = value, group= type, color = type)) +
  geom_line(aes(linetype = type))+
  facet_wrap(~method)+
  scale_color_stata()+
  geom_point(size = 4, aes(shape = type))+
  ggthemes::theme_few()+
  labs(x = "retrieval order", y = "similarity value")+
  theme(axis.title = element_text(face = "bold", size = rel(1)),
        strip.text= element_blank(),
          legend.title = element_text(face = "bold", size = rel(1)),
         plot.title = element_text(hjust = .5),
         axis.text.x = element_text(face = "bold", size = rel(1.2)))

## saved plot skeleton, modified/added features in powerpoint
#ggsave('plots/switch-example.pdf', clusterplot)  
```

# individual designations
## import individual designations

```{r}
# input corrections and exclusions made for forager

animal_corrections = readxl::read_excel("../forager_test/data/input_files/animal_corrections.xlsx") %>%
  rename(subject = SID, checked_words = entry) %>% select(subject, checked_words, final_word)

forager_evaluation = read_csv("../forager_test/output/animals_forager/evaluation_results.csv")%>%
  rename(subject = SID, checked_words = entry) %>%
  filter(evaluation != "FOUND")

# input the LEA participant designations

LEA_animals = read_csv("../forager_test/data/fluency_lists/reed_animals_RTs.csv") %>%
  filter(subject > 5000) %>%
  mutate(checked_words = str_replace_all(checked_words, " ", "")) %>%
  left_join(animal_corrections) %>% 
  left_join(forager_evaluation) %>% filter(!grepl('EXCLUDE', evaluation))%>%
  rowwise() %>%
  mutate(checked_words = ifelse(!is.na(final_word), final_word, checked_words)) %>%
  select(domain, subject,checked_words, participant_designated_switch) %>% 
  rename(cluster = checked_words)

LEA_foods = read_csv("../forager_test/data/fluency_lists/reed_foods_RTs.csv") %>%
  filter(subject > 5000) %>% select(domain, subject,checked_words, participant_designated_switch) %>%
  rename(cluster = checked_words)

LEA_occupations = read_csv("../forager_test/data/fluency_lists/reed_occupations_RTs.csv") %>%
  filter(subject > 5000) %>% select(domain, subject,checked_words, participant_designated_switch) %>%
  rename(cluster = checked_words)


LEA_data = rbind(LEA_animals, LEA_foods, LEA_occupations) %>%
  rowwise() %>%
  mutate(cluster = tolower(cluster)) %>%
  group_by(subject, domain) %>% mutate(response_number = row_number())%>%
  left_join(all_domains %>% mutate(subject = as.numeric(subject)) %>% filter(subject > 5000)) %>%
  mutate(norms_associative = ifelse(is.na(norms_associative), 0, norms_associative),
         norms_categorical = ifelse(is.na(norms_categorical), 0, norms_categorical))
```

## predict individual designations
```{r}

# Get the list of predictor variables (columns) from the dataframe
LEA_predictor_columns <- setdiff(names(LEA_data), 
                                 c("participant_designated_switch", "subject", "domain",
                                                    "response_number", "cluster"))

# Clean predictor column names in the dataframe
LEA_cleaned_data <- LEA_data %>%
  rename_with(clean_column_names, .cols = LEA_predictor_columns)

# Get the list of predictor variables (columns) from the dataframe
LEA_predictor_columns <- setdiff(names(LEA_cleaned_data), 
                                 c("participant_designated_switch", "subject", "domain",
                                                    "response_number", "cluster"))
## THIS PORTION TAKES A LONG TIME TO RUN ##
## UNCOMMENT TO RUN
## results have been saved into a file that can be directly read in and analyzed (see next chunk) ## 
# set.seed(123)
# glmer_model_results <- LEA_cleaned_data %>%
#   filter(participant_designated_switch != 2) %>%
#   group_by(domain) %>%
#   summarise(model = map(setNames(LEA_predictor_columns, LEA_predictor_columns), 
#                         ~ fit_model(df = cur_data(), 
#                                     column = .x, type = "glmer", dv = "participant_designated_switch", 
#                                    var_cutoff = .015)))
# 
# individual_model_results = glmer_model_results %>% unnest() %>%
#   mutate(Predictor = ifelse(Predictor == "norms_associative", "associative", 
#                             ifelse(Predictor == "norms_categorical", "categorical", Predictor))) %>%
#   separate(Predictor, sep = "_", 
#            into = c("Predictor", "param1", "p1_0", "p1_val", "param2", 
#                     "p2_0", "p2_val", "param3", "p3_0", "p3_val")) 
# 
# individual_model_results_table = individual_model_results %>%
#   filter(Predictor != "exp")%>%
#   group_by(domain, Predictor) %>%
#   slice_max(R_squared) %>%
#   unite("model", Predictor:p3_val) %>%
#   select(domain, model, R_squared, R_squared_CI_lower, R_squared_CI_upper, Fixed_Effect, AIC, BIC) %>%
#   mutate_if(is.numeric, round, 2)%>%
#   arrange(domain, desc(R_squared)) %>%
#   mutate(R = paste(R_squared, " [", R_squared_CI_lower, ",", R_squared_CI_upper, "]", sep = "")) %>%
#   select(domain, model, R, Fixed_Effect, AIC, BIC)
# 
# write.csv(individual_model_results,
#           file = "files/individual_model_results.csv", row.names = FALSE)
# 
# write.csv(individual_model_results_table,
#           file = "files/table_individual_model_results.csv", row.names = FALSE)

```

## Table 1 results

```{r}
individual_model_results_table = read_csv("files/table_individual_model_results.csv")
individual_model_results_table
```


## Figure 2: multimodaldelta model heatmap

```{r}
individual_model_results = read_csv("files/individual_model_results.csv")

options(scipen = 999)

multimodaldelta_models = individual_model_results %>% 
  filter(Predictor == "multimodaldelta") %>%
  unite("alpha", p1_0, p1_val, sep = ".", remove = FALSE) %>%
  mutate(alpha = as.numeric(alpha),2) %>%
  unite("rise", p2_0, p2_val, sep = ".", remove = FALSE) %>%
  unite("fall", p3_0, p3_val, sep = ".", remove = FALSE)%>%
  mutate(alpha = paste0("alpha=", as.numeric(alpha)),
         rise = as.numeric(rise), fall = as.numeric(fall))

multimodaldelta_models %>% 
  ggplot(aes(x = rise, y = fall, fill = R_squared)) +
  geom_tile()+
  facet_grid(domain~alpha)+
scale_x_continuous(breaks = c("0"= 0.0, ".25"=0.25, ".5" = 0.50,".75" = 0.75, "1" = 1.0))+
scale_y_continuous(breaks = c("0"= 0.0, ".25"=0.25, ".5" = 0.50,".75" = 0.75, "1" = 1.0))+
  geom_tile(color = 'black', stat = 'identity', size = 1, height = 0.25, width = 0.25,
              data = . %>% group_by(domain) %>% filter(R_squared == max(R_squared)))+
  scale_fill_gradient2(midpoint = 0.15, high = "darkgreen", low = "darkslategray") +
    theme_few() +
    labs(y = "fall parameter", x = "rise parameter",
          fill  =bquote(R^2 ~ "")) +
    theme(aspect.ratio = 1,
          axis.text.x = element_text(size = 8),
          axis.text.y = element_text(size = 8))

# ggsave('plots/multimodal_heatmap_participant.pdf', 
#        units = 'in', width = 10, height = 4)
```

## multiple regression

These models incrementally add each switch method to predict participant designations using the best-fitting parameter settings for models that have parameters.

### animals

```{r}
a = LEA_cleaned_data %>% filter(domain == "animals") %>% filter(participant_designated_switch != 2)

m1 = glmer(data = a, participant_designated_switch ~ 1  + (1|subject), family = binomial )
m2 = glmer(data = a, participant_designated_switch ~ norms_associative  + (1|subject), family = binomial )
m3 = glmer(data = a, participant_designated_switch ~ norms_associative + norms_categorical  + (1|subject), family = binomial )
m4 = glmer(data = a, participant_designated_switch ~ norms_associative + norms_categorical+ simdrop  + (1|subject), family = binomial )
m5 = glmer(data = a, participant_designated_switch ~ norms_associative + norms_categorical+ simdrop + delta_rise_0_75_fall_0_75 + 
             (1|subject), family = binomial )
# multimodal delta alpha = 1 so not running (redundant with delta rise)
m7 = glmer(data = a, participant_designated_switch ~ norms_associative + norms_categorical+ simdrop + delta_rise_0_75_fall_0_75  + multimodal_alpha_0_8 + (1|subject), family = binomial )
m8 = glmer(data = a, participant_designated_switch ~ norms_associative + norms_categorical+ simdrop + delta_rise_0_75_fall_0_75 + multimodal_alpha_0_8+ svd_cosine_0_9_gtom_0_7000000000000001 + (1|subject), family = binomial )

anova(m1, m2, m3, m4, m5, m7, m8)

summary(m8)
R = MuMIn::r.squaredGLMM(m8)[4]

animals_multiple_regression = tidy(m8) %>% mutate(domain = "animals", R = R)

```

### foods

```{r}
b = LEA_cleaned_data %>% filter(domain == "foods") %>% filter(participant_designated_switch != 2)

m1 = glmer(data = b, participant_designated_switch ~ 1  + (1|subject), family = binomial )
m2 = glmer(data = b, participant_designated_switch ~ norms_associative  + (1|subject), family = binomial )
m3 = glmer(data = b, participant_designated_switch ~ norms_associative + norms_categorical  + (1|subject), family = binomial )
m4 = glmer(data = b, participant_designated_switch ~ norms_associative + norms_categorical+ simdrop  + (1|subject), family = binomial )
m5 = glmer(data = b, participant_designated_switch ~ norms_associative + norms_categorical+ simdrop + delta_rise_1_0_fall_0_5 + (1|subject), family = binomial )
m6 = glmer(data = b, participant_designated_switch ~ norms_associative + norms_categorical+ simdrop + delta_rise_1_0_fall_0_5 + multimodaldelta_alpha_0_7000000000000001_rise_1_0_fall_0_5 + (1|subject), family = binomial )
# multimodal model has alpha = 1 so identical to simdrop, no need to test
m8 = glmer(data = b, participant_designated_switch ~ norms_associative + norms_categorical+ simdrop + delta_rise_1_0_fall_0_5 + multimodaldelta_alpha_0_7000000000000001_rise_1_0_fall_0_5 + svd_cosine_0_9_gtom_0_6000000000000001 + (1|subject), family = binomial )

anova(m1, m2, m3, m4, m5, m6, m8)
summary(m8)
R = MuMIn::r.squaredGLMM(m8)[4]
car::Anova(m8)
foods_multiple_regression = tidy(m8) %>% mutate(domain = "foods", R = R)

```

### occupations

```{r}
c = LEA_cleaned_data %>% filter(domain == "occupations") %>% filter(participant_designated_switch != 2)

m1 = glmer(data = c, participant_designated_switch ~ 1  + (1|subject), family = binomial )
# no norms for occupations, so not running those
m4 = glmer(data = c, participant_designated_switch ~ simdrop  + (1|subject), family = binomial )
m5 = glmer(data = c, participant_designated_switch ~ simdrop + delta_rise_0_75_fall_0_0 + (1|subject), family = binomial )
m6 = glmer(data = c, participant_designated_switch ~  simdrop + delta_rise_0_75_fall_0_0 + multimodaldelta_alpha_0_9_rise_0_75_fall_0_25 + (1|subject), family = binomial )
# multimodal model has alpha = 1 so identical to simdrop, no need to test
m8 = glmer(data = c, participant_designated_switch ~  simdrop + delta_rise_0_75_fall_0_0 + multimodaldelta_alpha_0_9_rise_0_75_fall_0_25 + svd_cosine_0_8_gtom_0_30000000000000004 + (1|subject), family = binomial )

anova(m1, m4, m5, m6, m8)
summary(m8)
R = MuMIn::r.squaredGLMM(m8)[4]
car::Anova(m8)

occ_multiple_regression = tidy(m8) %>% mutate(domain = "occupations", R = R)

```

### Table 2: combined multiple regression

```{r}
multiple_regression_all = rbind(animals_multiple_regression, foods_multiple_regression, 
                                occ_multiple_regression) %>%
  filter(effect == "fixed") %>%
  select(domain, R, term, estimate, std.error, statistic, p.value) %>%
   mutate(across(c(R,estimate, std.error, statistic), ~ round(., 2))) %>%
  mutate(across(c(p.value), ~ round(., 3)))
  
multiple_regression_all
```


# rater designations

## import rater data

```{r}
data = read_csv("../data/fluency-switch.csv")

sona_IDs= data %>% filter(!is.na(sona_id)) %>% select(ID) %>%distinct() %>% pull(ID)

data = data %>% mutate(population = ifelse(ID %in% sona_IDs, "sona", "prolific"))
prolific_IDs = data %>% filter(population == "prolific") %>% select(ID) %>% distinct() %>% pull(ID)


data_prolific_duplicates <- data %>%
  filter(type_of_trial == "prolific_id") %>%
  select(ID, response, recorded_at) %>% distinct() %>%
  separate(response, into = c("id", "prolific_id"), sep = ":") %>%
  mutate(prolific_id = gsub("[\\\\{}\"]", "", prolific_id)) %>%
  mutate(prolific_id = str_replace(prolific_id, "@.*", "")) %>%
  group_by(prolific_id) %>%
  mutate(min_recorded_at = min(recorded_at)) %>%
  ungroup() %>%
  filter(recorded_at != min_recorded_at) %>%
  select(ID) %>%
  distinct() %>% pull(ID)

final_prolific_IDs = prolific_IDs[!prolific_IDs %in% data_prolific_duplicates]
  

data = data %>% 
  filter(ID %in% c(sona_IDs, final_prolific_IDs))
  
length(unique(data$ID))

trials = data %>% filter(type_of_trial == "comparison") %>% mutate(cluster = tolower(cluster))
length(unique(trials$ID))
```

## apply exclusions

```{r}
## filter out IDs with incomplete data

insufficient_trials = trials %>%
  group_by(ID, domain, subject) %>%
  count() %>% 
  group_by(ID, domain) %>%
  count()%>%
  filter(n != 6)

trials = trials %>%
  filter(!(ID %in% insufficient_trials$ID))

## filter based on attention checks

attention = data %>% filter(type_of_trial == "attention" & !is.na(response)) %>%
  separate(current_pair, into = c("prev", "current"), sep = ",") %>%
  mutate(attn_corr = ifelse((stringdist(tolower(response), prev, method = "lv") < 2 ) | 
                              (stringdist(tolower(response), current, method = "lv") < 2 ), 1, 0))

ID_attn = attention %>%
  group_by(ID) %>%
  summarise(n_correct = sum(attn_corr))

insufficient_attentions = ID_attn %>%
  filter(n_correct < 15 & n_correct >0)

trials = trials %>%
  filter(!(ID %in% insufficient_attentions$ID)) %>%
  mutate(response = as.numeric(response)) 

## FINAL SAMPLE ##

length(trials %>% pull(ID) %>% unique())

actual_sample_IDs = trials %>% pull(ID) %>% unique()

nonfirst_trials = trials %>%
  filter(response!= 2)
```

## demographics

```{r}
demo_data = data %>% filter(type_of_trial == "demo") %>%
  filter(ID %in% actual_sample_IDs)

age_data = demo_data[grep('^\\{"Age', demo_data$response), ] %>%
  separate(response, into = c("Age", "Gender", "Education"), sep = ",") %>%
  mutate(
    Age = gsub("[^0-9]+", "", Age),          # Remove non-numeric characters from Age
    Gender = tolower(gsub('.*:"(.*)"', '\\1', Gender)),  # Extract the value between quotes in Gender
    Education = gsub("[^0-9]+", "", Education) # Remove non-numeric characters from Education
  )%>%
  mutate(
    Age = as.numeric(na_if(Age, "")),       # Replace empty cells in Age with NA
    Gender = na_if(Gender, ""), # Replace empty cells in Gender with NA
    Education = as.numeric(na_if(Education, "")) # Replace empty cells in Education with NA
  ) %>%
  mutate(Education = ifelse(Education  == 1415, 14.5, Education))%>%
  mutate(Gender = ifelse(Gender %in% c("he/him", "male", "make", "make ", "man", "m"), "men",
                         ifelse(Gender %in% c("female", "female ", "women", "woman"), "women",
                                ifelse(Gender %in% c("transgender male", "transgender"), "transgender", Gender))))
## AGE ##
age_data %>% summarize(m = mean(Age, na.rm = TRUE), sd = sd(Age, na.rm = TRUE))
## EDUCATION ##
age_data %>% summarize(m = mean(Education, na.rm = TRUE), sd = sd(Education, na.rm = TRUE))




## RACE ##
race_data = demo_data[grep('^\\{"Race', demo_data$response), ]%>%
  filter(grepl('^\\{"Race', response)) %>%
  mutate(
    Race = gsub('.*\\["(.*?)\\"]}', '\\1', response)
  ) %>%
  select(-response) %>%
  select(ID, Race) %>%
  mutate(RaceCat = ifelse(Race %in% c("White/Caucasian"), "White", 
                                   ifelse(Race %in% c("Black/African American"), "Black", 
                                          ifelse(Race %in% c("Asian"), "Asian", 
                                                 ifelse(Race %in% c("American Indian/Alaskan Native"), 
                                                        "American Indian/Alaskan Native",
                                                        "More/Other")))))

View(race_data %>%
  group_by(RaceCat) %>% 
  summarize(count = n()) %>%
   mutate(percent = count / sum(count) * 100))

## GENDER ##
View(age_data %>% group_by(Gender) %>% 
  summarize(count = n()) %>%
   mutate(percent = count / sum(count) * 100))


```

## merge with model predictions

```{r}
# get mean cluster-switch designations across all IDs for specific subject

trials_agg = nonfirst_trials %>%
  mutate(current_pair = str_replace(current_pair, "hello", cluster)) %>%
  group_by(subject, domain, response_number, current_pair) %>%
  summarise(mean_response = mean(response),
            num_responses = n())

trials_agg = trials_agg %>% 
  left_join(all_domains) %>%
  filter(!is.na(cluster))

```

## Figure 3: ratings with lexical similarity
```{r}
food_lexical = read_csv("../forager_test/output/foods_forager/lexical_results.csv") %>% 
  mutate(domain = "foods")
animal_lexical = read_csv("../forager_test/output/animals_forager/lexical_results.csv")%>% mutate(domain = "animals")
occupation_lexical = read_csv("../forager_test/output/occupations_forager/lexical_results.csv")%>% mutate(domain = "occupations")

all_lexical = rbind(food_lexical, animal_lexical, occupation_lexical) %>% 
  group_by(Subject, domain)%>%
  mutate(prev = lag(Fluency_Item))%>%
  mutate(current_pair = paste(prev,Fluency_Item, sep = ",")) %>%
  mutate(current_pair = str_replace_all(current_pair, " ", ""))%>%
  mutate(prev_freq = lag(Frequency_Value)) %>%
  rowwise()%>%
  mutate(avg_freq = sum(Frequency_Value, prev_freq)/2)

forager_evaluation = 
  read_csv("../forager_test/output/animals_forager/evaluation_results.csv")%>%
  rename(subject = SID) %>%
  filter(evaluation != "FOUND") %>%
  select(subject, entry, evaluation, replacement)%>%
  mutate(subject = as.character(subject))

animal_corrections = readxl::read_excel("../forager_test/data/input_files/animal_corrections.xlsx") %>%
  rename(subject = SID) %>% 
  select(subject, entry, final_word)%>%
  mutate(subject = as.character(subject))

plot_agg = nonfirst_trials %>%
  mutate(current_pair = str_replace(current_pair, "hello", cluster)) %>%
  separate(current_pair, into = c("prev", "current"), sep = ",") %>%
    mutate(prev = str_replace_all(prev, "[- ']", ""))%>%
  left_join(forager_evaluation %>% rename(prev = entry)) %>%
  mutate(prev = ifelse(is.na(evaluation), prev, replacement))%>%
  filter(!grepl('EXCLUDE', prev))%>%
  select(-c(evaluation, replacement)) %>%
  left_join(animal_corrections %>% rename(prev = entry))%>%
  mutate(prev = ifelse(is.na(final_word), prev, final_word))%>%
   mutate(current = str_replace_all(current, "[- ']", ""))%>%
  left_join(forager_evaluation %>% rename(current = entry)) %>%
  mutate(current = ifelse(is.na(evaluation), current, replacement))%>%
  filter(!grepl('EXCLUDE', current))%>%
  select(-c(evaluation, replacement, final_word)) %>%
  left_join(animal_corrections %>% rename(current = entry))%>%
  mutate(current = ifelse(is.na(final_word), current, final_word))%>%
  mutate(current = ifelse(current %in% c("business person", "busines person",
                                         "businesperson", "businessperson"),
                          "business", current),
         prev = ifelse(prev %in% c("business person", "busines person",
                                   "businesperson", "businessperson"),
                          "business", prev)) %>%
  unite("current_pair", prev:current, sep = ",") %>%
    group_by(domain, current_pair) %>%
  summarise(mean_response = mean(response),
            num_responses = n())

plot_all_lexical = all_lexical%>%
  left_join(plot_agg) %>% 
  filter(!is.na(mean_response)) %>% 
  mutate(Frequency_Value_scaled = avg_freq/10) %>%
  rename(`semantic similarity` = Semantic_Similarity,
         `phonological similarity` = Phonological_Similarity,
         `word frequency` = Frequency_Value_scaled) %>%
  pivot_longer(names_to = "cue", cols = c(`semantic similarity`, `phonological similarity`, `word frequency`))%>%
  mutate(cue = as.factor(cue),
         cue = fct_relevel(cue, "semantic similarity", "phonological similarity", "word frequency"))

plot_all_lexical %>%
  ggplot(aes(x = value, y =mean_response, group = domain, color = domain )) +
  geom_point(alpha = 0.1)+
  geom_smooth(method = "lm")+
  scale_y_continuous(breaks = c("0: cluster"= 0, "1: switch" = 1.0, ".2"= 0.2, ".4" = 0.4,
                                ".6" = 0.6, ".8" = 0.8))+
    coord_cartesian(ylim = c(0, 1)) +  # Set Y-axis limits
  labs(title = "",
       x = "mean lexical values",
       y = "mean ratings\nfor word pairs") +
  theme_minimal()+
  facet_wrap(~cue)+
  scale_color_gdocs()+
  theme(plot.background = element_rect(
    color = "white"),
    strip.text.x = element_text(size =rel(2)),
        axis.text = element_text(size =rel(1.5)),
        axis.title.x = element_text(size =rel(2)),
    axis.title.y = element_text(size =rel(1.5)),
        plot.title = element_text(hjust = .5, size = rel(1.2)))

#ggsave('plots/lexical_plot.pdf', units = "in",width = 12, height = 4)
```

## ratings lexical model
```{r}
ratings_lexical_model_semantic = lmer(data = plot_all_lexical %>% filter(cue == "semantic similarity"),
                             mean_response ~ value*domain + (domain | Subject))
car::Anova(ratings_lexical_model_semantic)
nobs(ratings_lexical_model_semantic)

ratings_lexical_model_phon = lmer(data = plot_all_lexical %>% filter(cue == "phonological similarity"),
                             mean_response ~ value*domain + (domain | Subject))
car::Anova(ratings_lexical_model_phon)
nobs(ratings_lexical_model_phon)

ratings_lexical_model_frequency = lmer(data = plot_all_lexical %>% filter(cue == "word frequency"),
                             mean_response ~ value*domain + (domain | Subject))
nobs(ratings_lexical_model_frequency)
car::Anova(ratings_lexical_model_frequency)



```


## predicting ratings

```{r}
rater_data <- trials_agg %>% 
  ungroup() %>%
  mutate(norms_associative = ifelse(is.na(norms_associative), 0, norms_associative),
         norms_categorical = ifelse(is.na(norms_categorical), 0, norms_categorical))

# Get the list of predictor variables (columns) from the dataframe
rater_predictor_columns <- setdiff(names(rater_data), c("mean_response", "subject", "domain", "response_number",
                                                  "current_pair", "num_responses", "cluster"))

# Clean predictor column names in the dataframe
rater_cleaned_data <- rater_data %>%
  rename_with(clean_column_names, .cols = rater_predictor_columns)

# Get the list of predictor variables (columns) from the dataframe
rater_predictor_columns <- setdiff(names(rater_cleaned_data), c("mean_response", "subject", "domain", "response_number",
                                                  "current_pair", "num_responses", "cluster"))

### NOTE: THIS PART TAKES A LONG TIME TO RUN ###
### files have been saved and can be directly imported and analyzed ###
### UNCOMMENT TO RUN ###
# rater_model_results <- rater_cleaned_data %>%
#   group_by(domain) %>%
#   summarise(
#     model = map(setNames(rater_predictor_columns, rater_predictor_columns), 
#                 ~ fit_model(df = cur_data(), column = .x, type = "lmer", dv = "mean_response", 
#                             var_cutoff = .015))
#   )
# 
# rater_model_results_unnested = rater_model_results %>% unnest() %>%
#   mutate(Predictor = ifelse(Predictor == "norms_associative", "associative", 
#                         ifelse(Predictor == "norms_categorical", "categorical", Predictor))) %>%
#   separate(Predictor, sep = "_", into = c("Predictor", "param1", "p1_0", "p1_val", 
#                                           "param2", "p2_0", "p2_val", "param3", "p3_0", "p3_val"))
# 
# rater_model_results_table = rater_model_results_unnested %>%
#   filter(Predictor != "exp")%>%
#   group_by(domain, Predictor) %>%
#   slice_max(R_squared) %>%
#   unite("model", Predictor:p3_val) %>%
#   select(domain, model, R_squared, R_squared_CI_lower, R_squared_CI_upper, Fixed_Effect, AIC, BIC) %>%
#   mutate_if(is.numeric, round, 2)%>%
#   arrange(domain, desc(R_squared)) %>%
#   mutate(R = paste(R_squared, " [", R_squared_CI_lower, ",", R_squared_CI_upper, "]", sep = "")) %>%
#   select(domain, model, R, Fixed_Effect, AIC, BIC)
# 
# write.csv(rater_model_results_unnested, file = "files/rater_model_results.csv", row.names = FALSE)
# 
# write.csv(rater_model_results_table, file = "files/table_rater_model_results.csv", row.names = FALSE)



```

## Table 3

```{r}
rater_model_results_table = read_csv("files/table_rater_model_results.csv")
rater_model_results_table
```

## multimodaldelta model heatmap

```{r}
rater_model_results_unnested = read_csv("files/rater_model_results.csv")

best_rating_models = rater_model_results_unnested %>%
  filter(Predictor != "exp")%>%
  group_by(domain, Predictor) %>%
  slice_max(R_squared) %>%
  unite("model", Predictor:p3_val) %>%
  select(domain, model, R_squared, R_squared_CI_lower, R_squared_CI_upper, Fixed_Effect, AIC, BIC) %>%
  mutate_if(is.numeric, round, 2)%>%
  arrange(domain, desc(R_squared)) %>%
  mutate(R = paste(R_squared, " [", R_squared_CI_lower, ",", R_squared_CI_upper, "]", sep = "")) %>%
  select(domain, model, R, Fixed_Effect, AIC, BIC)

multimodaldelta_models_rater = rater_model_results_unnested %>% 
  filter(Predictor == "multimodaldelta") %>%
  unite("alpha", p1_0, p1_val, sep = ".", remove = FALSE) %>%
  unite("rise", p2_0, p2_val, sep = ".", remove = FALSE) %>%
  unite("fall", p3_0, p3_val, sep = ".", remove = FALSE)%>%
  mutate(alpha = paste0("alpha=", as.numeric(alpha)),
         rise = as.numeric(rise), fall = as.numeric(fall))

multimodaldelta_models_rater %>% 
  ggplot(aes(x = rise, y = fall, fill = R_squared)) +
  geom_tile()+
  facet_grid(domain~alpha)+
  geom_tile(color = 'black', stat = 'identity', size = 1, width = 0.25, height = 0.25,
              data = . %>% group_by(domain) %>% filter(R_squared == max(R_squared)))+
scale_x_continuous(breaks = c("0"= 0.0, ".25"=0.25, ".5" = 0.50,".75" = 0.75, "1" = 1.0))+
scale_y_continuous(breaks = c("0"= 0.0, ".25"=0.25, ".5" = 0.50,".75" = 0.75, "1" = 1.0))+
  scale_fill_gradient2(midpoint = 0.2, high = "darkgreen", low = "darkslategray") +
    theme_few() +
    labs(y = "fall parameter", x = "rise parameter",
          fill  =bquote(R^2 ~ "")) +
    theme(aspect.ratio = 1,
          axis.text.x = element_text(size = 8),
          axis.text.y = element_text(size = 8))

#ggsave('plots/multimodal_heatmap_rater.pdf', units = 'in', width = 10, height = 4)
```


## exploratory: predict individual with rater

```{r}
exploratory_data = LEA_cleaned_data %>%
  mutate(subject = as.character(subject)) %>%
  select(domain, subject, cluster, participant_designated_switch, response_number ) %>%
  left_join((trials_agg %>% select(domain, subject, cluster, mean_response, response_number ))) %>%
  filter(!is.na(mean_response))

exploratory_lm = glmer(data = exploratory_data, participant_designated_switch ~ mean_response + (mean_response|subject),
                       family = binomial)
summary(exploratory_lm)
MuMIn::r.squaredGLMM(exploratory_lm)
```



# idiosyncratic score analysis

## compute transition scores

```{r}

## we want to see how "idiosyncratic" a response is based on how many people rated it as a cluster or switch

## need to fix corrections in nonfirst_trials so that merging happens correctly 

animal_corrections = readxl::read_excel("../forager_test/data/input_files/animal_corrections.xlsx") %>%
  rename(subject = SID, checked_words = entry) %>% select(subject, checked_words, final_word)

forager_evaluation = read_csv("../forager_test/output/animals_forager/evaluation_results.csv")%>%
  rename(subject = SID, checked_words = entry) %>%
  filter(evaluation != "FOUND")

LEA_data_idio = rbind(LEA_animals, LEA_foods, LEA_occupations) %>%
  group_by(domain, subject) %>%
  mutate(prev = lag(cluster)) %>%
  mutate(cluster= str_replace_all(cluster, " ", ""),
         prev = str_replace_all(prev, " ", ""))%>%
  mutate(current_pair = tolower(paste(prev, cluster, sep = ", ")))%>%
  filter(!is.na(prev))%>%
  select(domain, subject,current_pair, participant_designated_switch)

idio_data = nonfirst_trials %>% 
  mutate(subject = as.numeric(subject)) %>%
  #filter to contain data that has participant designations
  filter(subject > 5000) %>%
  select(domain, subject, current_pair, response_number, response, cluster) %>%
  separate(current_pair, into = c("prev", "current"), sep = ",") %>%
  mutate(current= str_replace_all(cluster, " ", ""),
         prev = str_replace_all(prev, " ", ""))%>%
  left_join(animal_corrections %>% rename(prev = checked_words)) %>% 
  rowwise() %>%
  mutate(prev = ifelse(!is.na(final_word), final_word, prev))%>%
  select(-final_word) %>%
    left_join(animal_corrections %>% rename(current = checked_words)) %>%  
  rowwise() %>%
  mutate(current = ifelse(!is.na(final_word), final_word, current))%>%
  unite("current_pair", prev:current, sep = ", ")%>%
  mutate(current_pair = str_replace(current_pair, "hello", cluster),
         subject = as.character(subject)) %>%
  group_by(domain, subject, response_number, current_pair, response) %>%
  summarize(N = n())%>%
  pivot_wider(names_from = response, values_from = N) %>%
  rename(cluster_N = "0", switch_N = "1") %>% 
  mutate(across(c(cluster_N, switch_N), ~coalesce(., 0))) %>%
  left_join(LEA_data_idio %>% mutate(subject = as.character(subject)))%>%
  mutate(idiosyncratic = ifelse(participant_designated_switch == 0, 
                                (switch_N / (cluster_N + switch_N)), 
                               (cluster_N / (cluster_N + switch_N)))) %>%
  # exclude items that were excluded from forager's evaluation
  # e.g., venusflytrap, etc.
  filter(!is.na(idiosyncratic))

## total N per list

total_n = idio_data %>% mutate(N = cluster_N + switch_N) %>% select(subject, N) %>% ungroup() %>% select(subject, N)%>% unique()
mean(total_n$N)
sd(total_n$N)

```

## Table 4: participant data

```{r}

View(idio_data %>% filter(subject == 50003) %>%
  filter(response_number %in% 45:52))
```


## lexical markers
```{r}
# are people who are more idiosyncratic use lexical cues differently? YES

idio_lexical = idio_data %>% 
  mutate(current_pair = str_replace_all(current_pair, " ", ""))%>%
  rename(Subject = "subject") %>% mutate(Subject = as.character(Subject)) %>%
  left_join(all_lexical %>% 
              mutate(Subject = as.character(Subject), 
                     current_pair = str_replace_all(current_pair, " ", ""))%>%
              select(domain, Subject, current_pair, 
                     Semantic_Similarity, Phonological_Similarity, avg_freq)) %>%
  mutate(Frequency_Value_scaled = avg_freq/10) %>%
  rename(`semantic similarity` = Semantic_Similarity,
         `phonological similarity` = Phonological_Similarity,
         `word frequency` = Frequency_Value_scaled) %>%
  pivot_longer(names_to = "cue", 
               cols = c(`semantic similarity`, `phonological similarity`, `word frequency`))%>%
  mutate(cue = as.factor(cue),
         cue = fct_relevel(cue, "semantic similarity", "phonological similarity", "word frequency"))



idio_lexical_semantic = lmer(data = idio_lexical %>% filter(cue == "semantic similarity"), 
                          idiosyncratic ~ value*domain + (domain|Subject))
nobs(idio_lexical_semantic)
car::Anova(idio_lexical_semantic)

idio_lexical_phonological = lmer(data = idio_lexical %>% filter(cue == "phonological similarity"), 
                          idiosyncratic ~ value*domain + (domain|Subject))
nobs(idio_lexical_phonological)
car::Anova(idio_lexical_phonological)

idio_lexical_frequency = lmer(data = idio_lexical %>% filter(cue == "word frequency"), 
                          idiosyncratic ~ value*domain + (domain|Subject))
nobs(idio_lexical_frequency)
car::Anova(idio_lexical_frequency)


```


## Figure 4: idiosyncratic lexical markers
```{r}
idio_lexical %>%
  ggplot(aes(x = value, y =idiosyncratic, group = domain, color = domain )) +
  geom_point(alpha = 0.1)+
  geom_smooth(method = "lm")+
  scale_y_continuous(breaks = c("0: no discordance"= 0, 
                                "1: high discordance" = 1.0, ".2"= 0.2, ".4" = 0.4,
                                ".6" = 0.6, ".8" = 0.8))+
    coord_cartesian(ylim = c(0, 1)) +  # Set Y-axis limits
  labs(title = "",
       x = "lexical values",
       y = "idiosyncratic score") +
  theme_minimal()+
  scale_color_gdocs()+
  facet_wrap(~cue)+
  theme(plot.background = element_rect(
    color = "white"),
    strip.text.x = element_text(size =rel(2)),
        axis.text = element_text(size =rel(1.5)),
        axis.title = element_text(size =rel(2)),
        plot.title = element_text(hjust = .5, size = rel(1.2)))

#ggsave('plots/idio_lexical_plot.pdf', units = "in",width = 15, height = 4)

```

## Figure 5: idio distribution

```{r}
LEA_idio = idio_data %>% group_by(domain, subject) %>%
  summarise(avg_idio = mean(idiosyncratic),
            items = n()) %>%
  mutate(domain = as.factor(domain))

LEA_idio %>%
  ggplot(aes(x=avg_idio, group = domain, fill = domain)) +
  geom_density(alpha = 0.4)+
  labs(title = "Distribution of Individual-Level Idiosyncratic Scores for Different Domains",
       x = "individual idiosyncratic score",
       y = "density") +
  theme_few()+
  scale_fill_excel()+
  theme(aspect.ratio = 1,
    plot.background = element_rect(
    color = "white"),
    strip.text.x = element_text(size =rel(2)),
        axis.text = element_text(size =rel(1.5)),
        axis.title = element_text(size =rel(2)),
        plot.title = element_text(hjust = .5, size = rel(1.2)))

#ggsave('plots/idio_distribution.pdf', units = "in")

```


## domain consistency

```{r}
## are people consistently idiosyncratic across domains?
## can you predict a score of a person on a new domain based on their score from an existing domain? YES


LEA_idio = idio_data %>% group_by(domain, subject) %>%
  summarise(avg_idio = mean(idiosyncratic),
            items = n()) %>%
  mutate(domain = as.factor(domain))

domain_idio_agg = LEA_idio %>%
  select(subject, domain, avg_idio) %>%
  pivot_wider(names_from = domain, values_from = avg_idio)

### NOTE: THIS CHUNK TAKES A LONG TIME ### 
### FILES HAVE BEEN SAVED AND CAN BE IMPORTED FOR ANALYSES (SEE NEXT CHUNK) ### 
### UNCOMMENT TO RUN ###

# Step 2: Train your original models and get Rsquared
# model_animals_foods <- summary(lm(animals ~ foods, data = domain_idio_agg))$r.squared
# model_animals_occupations <- summary(lm(animals ~ occupations, data = domain_idio_agg))$r.squared
# 
# model_foods_animals <- summary(lm(foods ~ animals, data = domain_idio_agg))$r.squared
# model_foods_occupations <- summary(lm(foods ~ occupations, data = domain_idio_agg))$r.squared
# 
# model_occupations_animals <- summary(lm(occupations ~ animals, data = domain_idio_agg))$r.squared
# model_occupations_foods <- summary(lm(occupations ~ foods, data = domain_idio_agg))$r.squared
# 
# # Set seed for reproducibility
# set.seed(123)
# 
# # Assuming 'domains' is a vector of domain names
# domains <- c("animals", "foods", "occupations")
# 
# # Initialize a matrix to store R-squared values
# num_permutations <- 1000
# r_squared_values <- matrix(NA, nrow = num_permutations * length(domains), ncol = 3)
# 
# row_counter <- 1
# 
# for (constant_column in domains) {
#   
#   shuffled_columns = domains[domains != constant_column]
# 
#   for (i in 1:num_permutations) {
#     
#     shuffled_column_1 = sample(domain_idio_agg %>% pull(shuffled_columns[1]))
#     shuffled_column_2 = sample(domain_idio_agg %>% pull(shuffled_columns[2]))
# 
#     df_shuffled = domain_idio_agg %>% select(subject, constant_column)%>%
#       cbind(shuffled_column_1, shuffled_column_2)
#       
#     formula1 = paste(constant_column, "~ shuffled_column_1")
#     formula2 = paste(constant_column, "~ shuffled_column_2")
#   
#     
#     model_1 <- lm(formula1, data = df_shuffled)
#     model_2 <- lm(formula2,  data = df_shuffled)
#   
#     r_squared_values[row_counter, 1] <- constant_column
#     r_squared_values[row_counter, 2] <- summary(model_1)$r.squared
#     r_squared_values[row_counter, 3] <- summary(model_2)$r.squared
#   
#     row_counter <- row_counter + 1
#   }
# }
# 
# 
# r_squared_values = as.data.frame(r_squared_values)
# 
# animals_data = r_squared_values %>% filter(V1 == "animals") %>%
#   pivot_longer(names_to = "model", cols = V2:V3) %>%
#   mutate(datatype = "permuted")%>%
#   rbind(data.frame(V1 = "animals", model = "V2", value= model_animals_foods, datatype = "original"), 
#                    data.frame(V1 = "animals", model = "V3", value= model_animals_occupations, datatype = "original") )%>%
#   mutate(value = as.numeric(value), model = as.factor(model), datatype = as.factor(datatype))%>%
#   mutate(model = ifelse(model == "V2", "animals ~ foods", "animals ~ occupations"))
# 
# foods_data = r_squared_values %>% filter(V1 == "foods") %>%
#   pivot_longer(names_to = "model", cols = V2:V3) %>%
#   mutate(datatype = "permuted")%>%
#   rbind(data.frame(V1 = "foods", model = "V2", value= model_foods_animals, datatype = "original"), 
#                    data.frame(V1 = "foods", model = "V3", value= model_foods_occupations, datatype = "original") )%>%
#   mutate(value = as.numeric(value), model = as.factor(model), datatype = as.factor(datatype))%>%
#   mutate(model = ifelse(model == "V2", "foods ~ animals", "foods ~ occupations"))
# 
# occupations_data = r_squared_values %>% filter(V1 == "occupations") %>%
#   pivot_longer(names_to = "model", cols = V2:V3) %>%
#   mutate(datatype = "permuted")%>%
#   rbind(data.frame(V1 = "occupations", model = "V2", value= model_occupations_animals, datatype = "original"), 
#                 data.frame(V1 = "occupations", model = "V3", value= model_occupations_foods, datatype = "original") )%>%
#   mutate(value = as.numeric(value), model = as.factor(model), datatype = as.factor(datatype))%>%
#   mutate(model = ifelse(model == "V2", "occupations ~ animals", "occupations ~ foods"))
# 
# combined_data= rbind(animals_data, foods_data, occupations_data)  %>%
#   rename(domain = "V1")
# 
# write.csv(combined_data, file = "files/scrambled_idiosyncratic.csv", row.names = FALSE)
```

### Figure 6 + permutation test
```{r}

combined_data = read_csv("files/scrambled_idiosyncratic.csv")
ggplot(combined_data, aes(x = value, fill = model)) +
  geom_histogram(binwidth = 0.01, position = "dodge") +
  facet_wrap(~domain, ncol = 1, scales = "free_y") +
  geom_vline(data = combined_data %>% filter(datatype == "original"), 
             aes(xintercept = value, color = model), linetype = "dashed") +
  labs(x = "R-squared", y = "Frequency") +
  theme_clean()
# save skeleton to pdf, rearrange legend in powerpoint
#ggsave('plots/idio_permutations.pdf', units = "in")



# Calculate the mean of shuffled R-squared values
permutation_test <- combined_data %>%
  group_by(domain, model) %>%
  summarise(p_value = {
    obs_value <- value[datatype == "original"]
    permuted_values <- value[datatype == "permuted"]
    formatted_p_value <- sprintf("%.6e", sum(permuted_values >= obs_value) / length(permuted_values))
    as.numeric(formatted_p_value)  # Convert back to numeric
  })

```

## num items

```{r}

## mean idio score
LEA_idio = idio_data %>% group_by(domain, subject) %>%
  summarise(avg_idio = mean(idiosyncratic),
            items = n()) %>%
  mutate(domain = as.factor(domain))

## do people who produce more idiosyncratic responses produce more items?: NO, marginal
items_lm = lm(data = LEA_idio, items ~ avg_idio*domain)
summary(items_lm)
car::Anova(items_lm)

LEA_idio %>%
ggplot(aes(x= items, y = avg_idio, group = domain, color = domain)) +
  geom_point() +
  geom_smooth(method = "lm")+
  theme_minimal()+
  scale_color_gdocs()+
  labs(x = "number of items", y = "participant idiosyncratic score")+
  theme(plot.background = element_rect(
    color = "white"),
    strip.text.x = element_text(size =rel(2)),
        axis.text = element_text(size =rel(1)),
        axis.title = element_text(size =rel(1.5)),
        plot.title = element_text(hjust = .5, size = rel(1.2)))
```

## participant clusters

```{r}
LEA_num_clusters = idio_data %>% 
  group_by(domain, subject)%>%
  summarise(n_switches = sum(participant_designated_switch)) %>%
  mutate(n_clusters = n_switches + 1) %>%
  left_join(LEA_idio)

idio_switch_model_participant = lm(data =LEA_num_clusters , 
                       avg_idio ~ n_clusters*domain)
nobs(idio_switch_model_participant)
car::Anova(idio_switch_model_participant)

model_predictions = predict(idio_switch_model_participant, newdata = LEA_num_clusters)
LEA_num_clusters$predicted_avg_idio = model_predictions

# Plot
idio_clusters_plot <- LEA_num_clusters %>%
  ggplot(aes(x = n_clusters, y = avg_idio, group = domain, color = domain)) +
  geom_point() +
  geom_line(aes(y = predicted_avg_idio)) +  # Use geom_line to add the predictions
  theme_few() +
  scale_color_gdocs() +
  labs(x = "number of clusters", y = "participant idiosyncratic score") +
  theme(strip.text.x = element_text(size = rel(2)),
        axis.text = element_text(size = rel(1)),
        aspect.ratio = 1,
        axis.title = element_text(size = rel(1.5)),
        legend.position = c(0.8, 0.8),
        plot.title = element_text(hjust = .5, size = rel(1.2)))

# Print the plot
print(idio_clusters_plot)

#ggsave('plots/idio_clusters_plot.pdf', idio_clusters_plot, height = 8, width = 8)  
```


# strategies

## consistency

```{r}
strategies = read_csv("../data/ID_strategies_long.csv") %>%
  filter(ID %in% actual_sample_IDs)

## category kappa
kappa_results <- strategies %>%
  group_by(category) %>%
  summarise(answer = list(irr::kappa2(select(cur_data(), AK, Nancy), weight = "unweighted"))) %>%
 mutate(kappa_value = map_dbl(answer, "value"),
        subjects = map_dbl(answer, "subjects"),
        raters = map_dbl(answer, "raters"),
        statistic = map_dbl(answer, "statistic"),
        p.value = map_dbl(answer, "p.value")) %>%
  select(category, subjects, raters, kappa_value, statistic,p.value) %>%
  mutate(kappa_value = ifelse(is.nan(kappa_value), 1, kappa_value))

mean(kappa_results$kappa_value)

## overall kappa
strategies %>%
  summarise(answer = list(irr::kappa2(select(cur_data(), AK, Nancy), weight = "unweighted"))) %>%
 mutate(kappa_value = map_dbl(answer, "value"),
        subjects = map_dbl(answer, "subjects"),
        raters = map_dbl(answer, "raters"),
        statistic = map_dbl(answer, "statistic"),
        p.value = map_dbl(answer, "p.value")) %>%
  select(subjects, raters, kappa_value, statistic,p.value)
```

## Table 5 (counts)
```{r}
strategies = strategies %>% 
  mutate(used = ifelse(Nancy == 1 | AK == 1, 1, 0))

counts = strategies %>% 
  group_by(category) %>%
  summarize(n_participants = sum(used)) %>%
  mutate(percent = n_participants/220) %>% 
  arrange(desc(percent))

counts
```


<!-- ## coding analysis (PRIOR to FINAL coding) -->

<!-- ```{r} -->
<!-- strategies = data %>%  -->
<!--   #filter(ID %in% trials$ID) %>% -->
<!--   filter(type_of_trial == "demo"  & str_detect(response, '^\\{"Q0":"')) %>% -->
<!--   filter(row_number() %% 2 != 0)%>% -->
<!--   mutate(response = str_extract(response, '(?<=Q0":").*?(?=")')) %>% -->
<!--   select(ID,response) -->

<!-- write.csv(strategies, file = "ID_strategies.csv", row.names = FALSE) -->
<!-- ``` -->



<!-- ```{r} -->
<!-- strategies = read_csv("../data/combined_strategies.csv") %>% -->
<!--   pivot_longer(names_to = "category", cols = semantic_associations_subcategories: -->
<!--                  vague_response_missing_or_misc_comment_unable_to_categorize_strategy) %>% -->
<!--   pivot_wider(names_from = "rater", values_from = value) -->

<!-- x <- strategies %>% -->
<!--   group_by(category) %>% -->
<!--   summarise(answer = list(irr::kappa2(select(cur_data(), AK, Nancy), weight = "unweighted"))) %>% -->
<!--  mutate(kappa_value = map_dbl(answer, "value"), -->
<!--         subjects = map_dbl(answer, "subjects"), -->
<!--         raters = map_dbl(answer, "raters"), -->
<!--         statistic = map_dbl(answer, "statistic"), -->
<!--         p.value = map_dbl(answer, "p.value")) %>% -->
<!--   select(category, subjects, raters, kappa_value, statistic,p.value) -->

<!-- maind = strategies %>% select(-Nancy) %>% -->
<!--   pivot_wider(names_from = category, values_from = Devin) -->
<!-- write.csv(maind, file = "devin.csv") -->

<!-- ak = read_csv("devin.csv") %>% -->
<!--   pivot_longer(names_to = "category", cols = semantic_associations_subcategories:vague_response_missing_or_misc_comment_unable_to_categorize_strategy) %>% -->
<!--   rename(AK = "value")%>% -->
<!--   select(-1) -->

<!-- strategies = strategies %>% left_join(ak) %>% -->
<!--   select(-Devin) %>% -->
<!--   mutate(neq = ifelse(Nancy == AK, 1, 0)) -->

<!-- write.csv(strategies, file="ID_strategies_long.csv", row.names = FALSE) -->
<!-- ``` -->






